ü§ñ Sorbonne AI Multi-Hub : Unified Chat Interface
Ce projet est une plateforme de discussion universelle d√©velopp√©e √† Sorbonne Universit√©. Elle permet de basculer instantan√©ment entre les meilleurs mod√®les du march√© (OpenAI, Google Gemini, Groq) au sein d'une interface unique et fluide.

üåü Points Forts
Multi-Fournisseur (Agnostique) : Support natif pour GPT-4o, Gemini 1.5 Pro et Llama 3.3 via une interface de s√©lection dynamique.

Comparaison en Temps R√©el : Id√©al pour tester la pertinence des r√©ponses entre diff√©rents mod√®les sur une m√™me question.

Architecture "Stateful" : Gestion de la m√©moire via st.session_state qui persiste m√™me lors du changement de mod√®le en cours de conversation.

Z√©ro Latence (Groq) : Int√©gration optimis√©e pour les mod√®les Llama ultra-rapides.

üõ†Ô∏è Stack Technique
Frontend : Streamlit (Composants Chat avanc√©s).

Orchestration : LangChain (m√©thodes invoke unifi√©es pour tous les fournisseurs).

Mod√®les support√©s :

OpenAI : gpt-4o, gpt-3.5-turbo

Google : gemini-1.5-flash, gemini-1.5-pro

Groq : llama-3.3-70b-versatile, llama-3.1-8b-instant

‚öôÔ∏è Installation Rapide
Clonage & D√©pendances :

Bash
git clone https://github.com/votre-username/sorbonne-ai-hub.git
pip install streamlit langchain-groq langchain-openai langchain-google-genai python-dotenv
Configuration des Cl√©s API :
Cr√©ez un fichier .env √† la racine :

Extrait de code
OPENAI_API_KEY=votre_cle
GOOGLE_API_KEY=votre_cle
GROQ_API_KEY=votre_cle
Lancement :

Bash
streamlit run app.py
üß† Fonctionnement Interne
Le code utilise une logique de branchement conditionnel :

L'utilisateur choisit un Provider via un menu d√©roulant.

Le script instancie dynamiquement l'objet llm correspondant gr√¢ce √† la modularit√© de LangChain.

L'historique des messages est format√© et envoy√© au mod√®le s√©lectionn√©, garantissant une continuit√© dans le dialogue peu importe l'IA choisie.
